{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:2.75em;color:purple; font-style:bold\">\n",
    "Ridge Regression using Julia (ScikitLearn):</p>\n",
    "<p style=\"font-family: Arial; font-size:2.25em;color:green; font-style:bold\">\n",
    "Kumar Rahul</p><br>\n",
    "\n",
    "\n",
    "ScikitLearn.jl implements the popular scikit-learn interface and algorithms in Julia. It supports both models from the Julia ecosystem and those of the scikit-learn library (via PyCall.jl).\n",
    "\n",
    "* More at: https://cstjean.github.io/ScikitLearn.jl/dev/man/python/\n",
    "* Examples at: https://github.com/cstjean/ScikitLearn.jl/blob/master/docs/src/man/examples.md\n",
    "\n",
    "\n",
    "### We will be using DAD hospital data in this exercise. Refer the Exhibit 1 to understand the feature list. Use the DAD Hospital data and answer the below questions.\n",
    "\n",
    "1.\tLoad the dataset in Jupyter Notebook using CSV\n",
    "2.\tBuild a correlation matrix between all the numeric features in the dataset.\n",
    "3.\tBuild a new feature named BMI using body height and body weight. Include this as a part of the data frame created in step 1.\n",
    "4.\tCreate a new data frame with the numeric features and categorical features as dummy variable coded features. Which features will you include for model building and why?\n",
    "5.\tSplit the data into training set and test set. Use 80% of data for model training and 20% for model testing. \n",
    "6.\tBuild a model using age as independent variable and cost of treatment as dependent variable.\n",
    "    > * Is age a significant feature in this model?\n",
    "    * What inferences can be drawn from this model? \n",
    "7.\tBuild a model with statsmodel.api to estimate the total cost to hospital. How do you interpret the model outcome? Report the model performance on the test set.\n",
    "8.\tBuild a model with statsmodel.formula.api to estimate the total cost to hospital and report the model performance on the test set. What difference do you observe in the model built here and the one built in step 7.\n",
    "9.\tBuild a model using sklearn package to estimate the total cost to hospital. What difference do you observe in this model compared to model built in step 7 and 8.\n",
    "10. Build a model using lasso, ridge and elastic net regression. What differences do you observe?\n",
    "\n",
    "**PS: Not all the questions are being answered as a part of the same notebook. You are encouraged to answer the questions if you find them missing.**\n",
    "\n",
    "**Exhibit 1**\n",
    "\n",
    "|Sl.No.|Variable|\tDescription|\n",
    "|------|--------|--------------|\n",
    "|1|Age|\t Age of the patient in years|\n",
    "|2|Body Weight|\t Weight of the patient in Kilograms|\n",
    "|3|Body Height| \tHeight of the patient in cm|\n",
    "|4|HR Pulse|\t Pulse of patient at the time of admission|\n",
    "|5|BP-High|\t High BP of patient (Systolic)|\n",
    "|6|BP-Low|\t Low BP of patient (Diastolic)|\n",
    "|7|RR|\t Respiratory rate of patient|\n",
    "|8|HB|\t Hemoglobin count of patient|\n",
    "|9|Urea|\t Urea levels of patient|\n",
    "|10|Creatinine|\t Creatinine levels of patient|\n",
    "|11|Marital Status|\t Marital status of the patient|\n",
    "|12|Gender|\t  Gender code for patient|\n",
    "|13|Past Medical History Code|\t Code given to the past medical history of the Patient|\n",
    "|14|Mode of Arrival|\t Way in which the patient arrived the hospital|\n",
    "|15|State at the Time of Arrival|\t State in which the patient arrived|\n",
    "|16|Type of Admission|\t Type of admission for the patient|\n",
    "|17|Key Complaints Code|\t Codes given to the key complaints faced by the patient|\n",
    "|18|Total Cost to Hospital|\t Actual cost incurred by the hospital|\n",
    "|19|Total Length of Stay|\t Number of days patient stayed in the hospital|\n",
    "|20|Length of Stay - ICU|\t Number of days patient stayed in the ICU|\n",
    "|21|Length of Stay - Ward|\t Number of days patient stayed in the ward|\n",
    "|22|Implant used (Y/N)|\t Any implant done on the patient|\n",
    "|23|Cost of Implant|\t Total cost of all the implants done on the patient, if any|\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "# Code starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use below mentioned libraries for **data import, processing and visulization**. As we progress, we will use other specific libraries for model building and evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "libraries, echo=TRUE, message=FALSE, warning=FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#import pandas as pd \n",
    "#import numpy as np\n",
    "#import seaborn as sn # visualization library based on matplotlib\n",
    "#import matplotlib.pylab as plt\n",
    "\n",
    "#the output of plotting commands is displayed inline within Jupyter notebook\n",
    "#%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Pkg.add(\"Package-name\") to install the packages before proceeding further.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Statistics\n",
    "using FreqTables\n",
    "using StatsBase\n",
    "using Gadfly\n",
    "using Printf\n",
    "using MLJ ##Machine Learning Julia, schema() from this package.\n",
    "using ScikitLearn ##Machine Learning using SciKitLearn\n",
    "using JLD ##To save model object\n",
    "using PyCallJLD #to save model object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Import and Manipulation\n",
    "\n",
    "### 1. Importing a data set\n",
    "\n",
    "_Give the correct path to the data_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the display settings for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"COLUMNS\"] = 1000\n",
    "\n",
    "ENV[\"LINES\"] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "readData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df = CSV.read( \"../DAD_hospital/data/DAD_Case_Data_Corrected.csv\", DataFrame, \n",
    "                    delim = \",\", header =1,\n",
    "                    normalizenames=true,\n",
    "                    missingstrings = [\"\", \" \"]\n",
    "                    )\n",
    "head(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rename!(raw_df, lowercase.(names(raw_df)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping SL No as these will not be used for any analysis or model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#if Set([\"sl no\"]) in names(raw_df){\n",
    "#    raw_df.drop(['sl no'],axis=1, inplace=True)\n",
    "#    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"sl_no\" in names(raw_df)\n",
    "    select!(raw_df, Not([\"sl_no\"]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional: To iterate over rows and columns of a dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eachcol(raw_df);\n",
    "eachrow(raw_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Structure of the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "summarizeData, echo=TRUE,tidy=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very informative as it does not print the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "summarizeData, echo=TRUE,tidy=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "eltypes(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'=>' is a pair operator in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "summarizeData, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Dict(names(raw_df) .=> eltype.(eachcol(raw_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can use schema() from MLJ package to get the data types. This package has useful functions for OneHotEncoding etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get numeric features from the data and find the corelation amongst numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical_features = [x for x in raw_df.select_dtypes(include=[np.number])]\n",
    "#numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = names(raw_df[(<:).(eltypes(raw_df),Union{Number,Missing})])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "* **Build a correlation matrix between all the numeric features in the dataset.**\n",
    "\n",
    "This is how it was done in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#numerical_features_df = raw_df.select_dtypes(include=[np.number])\n",
    "#numerical_features_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get categorical features from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_features = [x for x in raw_df.select_dtypes(include=[np.object])]\n",
    "#categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_features = names(raw_df[(<:).(eltypes(raw_df),Union{String,Missing})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(raw_df, :all, cols=numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(raw_df, :all, cols=categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(raw_df, :min,:max,:nunique,:first,:last,:eltype, cols=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarizing the dataset\n",
    "Create a new data frame and store the raw data copy. This is being done to have a copy of the raw data intact for further manipulation if needed. The *dropna()* function is used for row wise deletion of missing value. The axis = 0 means row-wise, 1 means column wise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "createDataCopy, echo=TRUE,tidy=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "#filter_df = raw_df.dropna()\n",
    "#list(filter_df.columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "createDataCopy, echo=TRUE,tidy=TRUE",
    "autoscroll": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_df = copy(dropmissing(raw_df))\n",
    "head(filter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'=>' is a pair operator in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict(names(filter_df) .=> eltype.(eachcol(filter_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first start by printing the unique labels in categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@show Set(filter_df[:,\"gender\"]);\n",
    "unique(filter_df[:,\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for f in categorical_features:\n",
    "#    print(\"\\nThe unique labels in {} is {}\\n\".format(f, filter_df[f].unique()))\n",
    "#    print(\"The values in {} is \\n{}\\n\".format(f,  filter_df[f].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The '@' is used before printf as 'printf' is a macro and not a function.  It can parse and interpret the format string at compile time and generate custom code for that specific format string. \n",
    "\n",
    "More at: https://stackoverflow.com/questions/19783030/in-julia-why-is-printf-a-macro-instead-of-a-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for f in categorical_features\n",
    "    #print(repr(f)) ## to convert symbol to categorical name.\n",
    "    unq = unique(filter_df[:, f]) ## Set(filter_df[:, (f)]) also works.\n",
    "    val_cnt = StatsBase.countmap(filter_df[:, (f)])\n",
    "    @printf(\"\\nThe unique labels in %s is %s \\n\", f, unq)\n",
    "    @printf(\"\\nThe unique labels in %s is %s \\n\", f, val_cnt)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clubbing some of the feature labels together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_df['past_medical_history_code']=np.where(\n",
    "#    (filter_df['past_medical_history_code'] =='hypertension1') |\n",
    "#    (filter_df['past_medical_history_code'] =='hypertension2') |\n",
    "#    (filter_df['past_medical_history_code'] =='hypertension3'), \n",
    "#    'hypertension', filter_df['past_medical_history_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.` is a broadcasting operator in julia. So, f.(a, b) means \"apply f elementwise to a and b\".\n",
    "\n",
    "More at: https://docs.julialang.org/en/v1/manual/arrays/#Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df[:,\"past_medical_history_code\"].= ifelse.(\n",
    "        (filter_df[:,\"past_medical_history_code\"] .== \"hypertension1\") .|\n",
    "        (filter_df[:,\"past_medical_history_code\"] .== \"hypertension2\") .| \n",
    "        (filter_df[:,\"past_medical_history_code\"] .== \"hypertension3\"),\n",
    "    \"hypertension\", filter_df[:,\"past_medical_history_code\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(filter_df[filter_df.past_medical_history_code .== \"hypertension\",:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countmap(filter_df.past_medical_history_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_df['past_medical_history_code']=np.where(\n",
    "#    (filter_df['past_medical_history_code'] =='Diabetes1') |\n",
    "#    (filter_df['past_medical_history_code'] =='Diabetes2'), \n",
    "#    'diabetes', filter_df['past_medical_history_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df[(filter_df.past_medical_history_code .==\"Diabetes1\") .| \n",
    "            (filter_df.past_medical_history_code .==\"Diabetes2\"),\"past_medical_history_code\"] .= \"Diabetes\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countmap(filter_df.past_medical_history_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df[(filter_df.key_complaints_code .==\"other- respiratory\") .| \n",
    "         (filter_df.key_complaints_code .==\"PM-VSD\") .|\n",
    "        (filter_df.key_complaints_code .==\"CAD-SVD\") .|\n",
    "        (filter_df.key_complaints_code .==\"CAD-VSD\") .|\n",
    "        (filter_df.key_complaints_code .==\"other-nervous\") .|\n",
    "        (filter_df.key_complaints_code .==\"other-general\")\n",
    "        ,\"key_complaints_code\"] .= \"others\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countmap(filter_df.key_complaints_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise:\n",
    "\n",
    "* **Calculate the average across all the numeric features w.r.t categorical feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def group_by (categorical_features):\n",
    "#    return filter_df.groupby(categorical_features).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group_by(\"past_medical_history_code\")\n",
    "#group_by(\"key_complaints_code\")\n",
    "#group_by(\"marital_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculating BMI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#filter_df['bmi'] = filter_df.body_weight/(np.power((filter_df.body_height/100),2))\n",
    "#filter_df['bmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df[:,\"bmi\"] = filter_df.body_weight./(filter_df.body_height./100).^2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Visualizing the Data using Gadfly\n",
    "\n",
    "* **Write a custom function to create bar plot to visualize the average of numeric features w.r.t each categorical feature. Say, average age w.r.t gender.**\n",
    "\n",
    "This is how one may do using seaborn in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_df[numerical_features].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def bar_plot(xlabel,ylabel):\n",
    "#    sn.barplot(x = xlabel, y = ylabel, data= filter_df)\n",
    "#    plt.xlabel(xlabel, size = 14)\n",
    "#    plt.ylabel(ylabel, size = 14)\n",
    "#    #plt.grid(True)\n",
    "#    x1,x2,y1,y2 = plt.axis()\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#numerical_features_set = ['age','rr']\n",
    "#categorical_features_set = ['gender','marital_status']\n",
    "\n",
    "#for c in categorical_features_set:\n",
    "#    for n in numerical_features_set:\n",
    "#        bar_plot(c,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Write your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model using sklearn:\n",
    "\n",
    "Remove the response variable from the dataset. To get symbols:\n",
    "\n",
    "* Type \\in (TAB) - ∈ or \n",
    "* \\notin (TAB) - ∉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using ScikitLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_features = [\"body_weight\",\"body_height\",\n",
    "                    \"creatinine\",\"state_at_the_time_of_arrival\",\n",
    "                    \"total_amount_billed_to_the_patient\",\"concession\",\n",
    "                    \"actual_receivable_amount\",\"total_length_of_stay\",\n",
    "                    \"length_of_stay_icu\",\"length_of_stay_ward\",\n",
    "                    \"total_cost_to_hospital\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional: Way to create a list of features the python way:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[x for x in names(raw_df) if (x!=\"age\") && (x!=\"gender\")];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_features = [x for x in names(filter_df) if x not in removed_features] ##Python\n",
    "\n",
    "X_features = [x for x ∈ names(filter_df) if x ∉ removed_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_features ∉ X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_features ∈ X_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Encoding using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric = names(filter_df[:,X_features][(<:).(eltypes(filter_df[:,X_features]),Union{Number,Missing})])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_categoric = names(filter_df[:,X_features][(<:).(eltypes(filter_df[:,X_features]),Union{String,Missing})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##We will use LabelBinarizer\n",
    "\n",
    "@sk_import preprocessing:(LabelBinarizer)#, StandardScaler, OneHotEncoder, LabelEncoder, MultiLabelBinarizer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ScikitLearn.DataFrameMapper can be used to do dummy variable coding. The DataFramemapper won't be available until DataFrames is imported. We can individually apply label binarizer but it is not efficient.\n",
    "\n",
    "Label Binarizer is an SciKitLearn class that accepts Categorical data as input and returns a matrix. Unlike Label Encoder, which can be used to assign unique value to each label,  Label Binarizer encodes the data into dummy variables indicating the presence of a particular label or not.\n",
    "\n",
    "One can refer to https://scikit-learn.org/stable/modules/preprocessing.html for different methods from sklearn python which can be used in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([ \n",
    "                        ( :key_complaints_code  , LabelBinarizer() )#,\n",
    "                        #( :gender  , LabelBinarizer() )\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countmap(filter_df.key_complaints_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_transform!(mapper, copy(filter_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the documentation gives this option but there seems to be some bug or passing a list is not supported for now. Below code will not work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapper = DataFrameMapper([ \n",
    "#                        ([ Symbol.(X_categoric) ] , LabelBinarizer()),\n",
    "#                        ( [ Symbol.(X_numeric) ], nothing )]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workaround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_col = Symbol.(X_categoric)\n",
    "cat_feature_defs = [(cat_col_name, LabelBinarizer()) for cat_col_name in cat_col]\n",
    "cat_mapper = DataFrameMapper(cat_feature_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_col = Symbol.(X_numeric)\n",
    "num_feature_defs = [(num_col_name, nothing) for num_col_name in num_col]\n",
    "num_mapper = DataFrameMapper(num_feature_defs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fit_transform!(LabelBinarizer(), filter_df)\n",
    "X1 = fit_transform!(cat_mapper, (filter_df));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = fit_transform!(num_mapper, (filter_df));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = convert(DataFrame,hcat(X1,X2)) #Can convert\n",
    "head(X3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLJ Package\n",
    "\n",
    "MLJ (Machine Learning in Julia) is a toolbox written in Julia providing a common interface and meta-algorithms for selecting, tuning, evaluating, composing and comparing over 150 machine learning models written in Julia and other languages. In particular MLJ wraps a large number of scikit-learn models.\n",
    "\n",
    "https://alan-turing-institute.github.io/MLJ.jl/dev/list_of_supported_models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get the names of models supported by MLJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models for which code is already loaded can be found with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localmodels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search a model pass the name as a string. All the models matching the name will be shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models(\"regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Categorical Encoding using MLJ \n",
    "\n",
    "By default, the scientific types of categoroical variable is \"Textual\". We need to coerce it to Categorical before applying OneHotEncoding.\n",
    "\n",
    "More on Scientific types and internal working at: https://alan-turing-institute.github.io/MLJ.jl/dev/mlj_cheatsheet/#Scitypes-and-coercion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "schema(filter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To coerce a particular column to continuos or multiclass, we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(coerce!(copy(filter_df), :hb => Continuous, :gender => Multiclass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to coerce all Textual column to multiclass, we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(coerce!(filter_df, Textual => Multiclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema(filter_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "Why hb is being shown with scientific type as 'Count' even though we just coerced it to Continuous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dummy variable encoding is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_X_df = pd.get_dummies(filter_df[X_features], drop_first = True )\n",
    "#encoded_X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform is same as calling predict function in python. In MLJ:\n",
    "* For supervised problem, we will call predict\n",
    "* For unsupervised problem, it will be transform\n",
    "\n",
    "The function 'machine()' binds a model (i.e., a choice of algorithm + hyperparameters) to data. A machine is also the object storing learned parameters. Under the hood, calling fit! on a machine calls either MLJBase.fit or MLJBase.update, depending on the machine's internal state (as recorded in private fields old_model and old_rows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = machine(MLJ.OneHotEncoder(drop_last=true), filter_df[:,X_features])\n",
    "MLJ.fit!(ohe)\n",
    "encoded_X_df = MLJ.transform(ohe, filter_df[:,X_features]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(encoded_X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Matrix(encoded_X_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = filter_df[:,\"total_cost_to_hospital\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data split using Python\n",
    "\n",
    "The train and test split can also be done using the **sklearn module**. If we use @sk_import to call the train_test_split function from model_selection module, we will get a warning message. Reason, the native ScikitLearn package in Julia has already defined train_test_split() in CrossValidation module, so better to use it from this module.\n",
    "\n",
    "In MLJ, we have partition() function to do the split but we are not using it as of now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#@sk_import model_selection: (train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ScikitLearn.CrossValidation: train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split ##Python code \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show size(X_train)\n",
    "@show size(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building: Using the **sklearn** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretModel, echo=TRUE, message=FALSE, warning=FALSE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "#ridge_reg_model = linear_model.Ridge(alpha = 0.5) #alpha = 0 is same as simple regression with OLS\n",
    "\n",
    "# Train the model using the training sets\n",
    "#ridge_reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sk_import linear_model: (LinearRegression, Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg_model = ScikitLearn.fit!(Ridge(alpha=0.5), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(ridge_reg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the model is as simple as calling the `fit` method for `Ridge`. However, since we would like to select the best value of alpha, lets try to do it using the below function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "y_pred = ScikitLearn.predict(ridge_reg_model,X_test);\n",
    "y_pred = ridge_reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", ridge_reg_model.coef_)\n",
    "print(\"Intercept: \\n\", ridge_reg_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@which mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "@sk_import metrics: (mean_squared_error, r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error\n",
    "@printf(\"The mean squared error is %d\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance score: 1 is perfect prediction\n",
    "\n",
    "@printf(\"The mean squared error is %.2f\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search with cross validation\n",
    "\n",
    "To use RandomizedSearchCV, create a parameter grid from where sample will be picked during model building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = collect(0.1:0.1:10)\n",
    "\n",
    "# Create the grid\n",
    "random_grid = Dict(\"alpha\" => alpha)\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Grid Search\n",
    "\n",
    "To report the performance on the selected KPI use `sklearn.metrics.SCORERS.keys()` to get the list of all the metrics and pass the relevant one in `RandomizedSearchCV` or `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@sk_import metrics: (SCORERS)\n",
    "\n",
    "#SCORERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "#from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using ScikitLearn.CrossValidation: GridSearchCV\n",
    "@sk_import model_selection: (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 3 fold cross validation, \n",
    "\n",
    "ridge_reg_model = Ridge()\n",
    "ridge_best_model = GridSearchCV(estimator = ridge_reg_model, \n",
    "                               param_grid = random_grid, \n",
    "                                scoring = \"r2\",\n",
    "                               cv = 3, verbose=0)\n",
    "# Fit the random search model\n",
    "#ridge_best_model.fit(X_train, y_train)\n",
    "\n",
    "ScikitLearn.fit!(ridge_best_model,X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the parameter\n",
    "\n",
    "The best model has the following parameter selected from the random search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_best_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The prediction on test data.\n",
    "\n",
    "The prediction can be carried out by **defining functions** as well. Below is one such instance wherein a function is defined and is used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Rmd_chunk_options": "caretPrediction, echo=TRUE",
    "autoscroll": false
   },
   "outputs": [],
   "source": [
    "y_pred = ScikitLearn.predict(ridge_best_model,X_test);\n",
    "y_pred = ridge_best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show mean_squared_error(y_test, y_pred)\n",
    "@show r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment - Save model\n",
    "\n",
    "Save the model using JLD and PyCallJLD (Neeed if using @sk_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib\n",
    "#import joblib\n",
    "#import pickle\n",
    "\n",
    "#joblib.dump( ridge_best_model, \"ridge_best_model.joblib\" )\n",
    "#pickle.dump(ridge_best_model,open(\"ridge_best_model.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JLD.save(\"ridge_best_model.jld\", \"model\", ridge_best_model)\n",
    "#@save \"ridge_best_model1.JLD\" ridge_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model on New Cases\n",
    "\n",
    "We can load the model object for later use. Assuming that X_test is a new data on which we will want to use the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = JLD.load(\"ridge_best_model.jld\", \"model\")    # Load it back\n",
    "\n",
    "#@load \"ridge_best_model1.JLD\" ridge_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict( X_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### End of Document\n",
    "\n",
    "***\n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "Rmd_header": {
   "author": "Kumar Rahul",
   "date": "9 September 2016",
   "output": "word_document",
   "title": "Logistic Regression using Caret Package"
  },
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
