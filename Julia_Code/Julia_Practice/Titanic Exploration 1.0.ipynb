{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3.75em;color:purple; font-style:bold\"><br>\n",
    "Introduction to CSV.jl and DataFrames.jl</p><br>\n",
    "<p style=\"font-family: Arial; font-size:2.00em;color:green; font-style:bold\">\n",
    "Kumar Rahul</p>\n",
    "\n",
    "**_DataFrames_** is a Julia library for tabular data manipulation. It offers a number of data exploration, cleaning and transformation operations that are critical in working with data in Julia. Similar to pandas in Python and data.table, dplyr in R. DataFrames.jl work well with a range of file formats such as CSVs (using CSV.jl), Apache Arrow (using Arrow.jl) Stata, SPSS, and SAS files (using StatFiles.jl), and reading and writing parquet files (using Parquet.jl)\n",
    "\n",
    "\n",
    "Objects of the DataFrame type represent a data table as a series of vectors, each corresponding to a column or variable.  After a brief introduction to these two data structures and data ingestion, the key features of *dataframes* this notebook covers are:\n",
    ">* Generating descriptive statistics on data\n",
    "* Data cleaning using built in dataframes functions\n",
    "* Frequent data operations for subsetting, filtering, insertion, deletion and aggregation of data\n",
    "* Merging multiple datasets using dataframes\n",
    "\n",
    "Few other libraries which people may have to use with DataFrames for advanced data wrangling:\n",
    "\n",
    "> * Impute.jl: various methods for handling missing data in vectors, matrices and tables.\n",
    "* DataFramesMeta.jl: A range of convenience functions for DataFrames.jl that augment select and transform to provide a user experience similar to that provided by dplyr in R.\n",
    "* Query.jl: Query.jl provides a single framework for data wrangling that works with a range of libraries, including DataFrames.jl, other tabular data libraries (more on those below), and even non-tabular data. Provides many convenience functions analogous to those in dplyr in R or LINQ. SQL like querying structure.\n",
    "* StatsModels.jl: For converting heterogeneous DataFrame into homogenous matrices for use with linear algebra libraries or machine learning applications that don't directly support DataFrames. Will do things like convert categorical variables into indicators/one-hot-encodings, create interaction terms, etc.\n",
    "\n",
    "**Additional Recommended Resources:**\n",
    "* `DataFrames` documentation: https://dataframes.juliadata.org/stable/\n",
    "* `DataFrames Cheatsheet`: https://www.ahsmart.com/pub/data-wrangling-with-data-frames-jl-cheat-sheet/\n",
    "* Comparing with R & Python: https://dataframes.juliadata.org/stable/man/comparisons/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Pkg\n",
    "#Pkg.add(\"DataFrames\") ##Mandatory\n",
    "#Pkg.add(\"CSV\") ##Mandatory\n",
    "#Pkg.add(\"Statistics\") ## Mandatory - For statistics like mean, quaretile etc.\n",
    "\n",
    "#Pkg.add(\"FreqTables\") ## Good to have for Pivoting\n",
    "#Pkg.add(\"StatsBase\") ### Good to have - counting, ranking, covariances, sampling, and empirical density estimation.\n",
    "\n",
    "#Pkg.add(\"TableView\") ## optional - to render a table\n",
    "#Pkg.add(\"DataFramesMeta\") ##optional - Data manipulation add-on to DataFrames.jl. SQL style statements - Query.jl 42 or DataFramesMeta.jl\n",
    "\n",
    "#Pkg.add(\"WebIO\") ##Not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Statistics\n",
    "using FreqTables\n",
    "using StatsBase\n",
    "using DataFramesMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using WebIO\n",
    "#WebIO.install_jupyter_nbextension()\n",
    "#using TableView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General settings \n",
    "\n",
    "By default, Julia uses 80 horizontal space to show columns and 30 vertical space to show rows.\n",
    "> * Check the default number of rows and columns which are displayed. \n",
    "* Change the default setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"COLUMNS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"LINES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no analogus of the below python command here:\n",
    "\n",
    "    > from IPython.core.interactiveshell import InteractiveShell\n",
    "    > InteractiveShell.ast_node_interactivity = \"all\"\n",
    "    \n",
    "To display all objects from a code cell, use as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2;\n",
    "println(a);\n",
    "b = 4;\n",
    "@show b;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use of colon, is optional, and it suppresses the default print from the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe\n",
    "\n",
    "Several ways to create a dataframe. One being shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame()\n",
    "df.A = 1:8\n",
    "df.B = [\"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"M\", \"F\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case - Titanic Dataset\n",
    "\n",
    "The data has been taken from : https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "The data description:\n",
    "\n",
    "\n",
    "> * PassengerId: type should be integers\n",
    "* Survived: Survived or Not\n",
    "* Pclass: Class of Travel\n",
    "* Name: Name of Passenger\n",
    "* Sex: Gender\n",
    "* Age: Age of Passengers\n",
    "* SibSp: Number of Sibling/Spouse aboard\n",
    "* Parch: Number of Parent/Child aboard\n",
    "* Ticket\n",
    "* Fare\n",
    "* Cabin\n",
    "* Embarked: The port in which a passenger has embarked. C - Cherbourg, S - Southampton, Q = Queenstown\n",
    "\n",
    "\n",
    "We will use the titanic dataset to understand data load and munging using DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()\n",
    "homedir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd(\"./Julia_Practice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset, which is in csv format\n",
    "\n",
    "Pandas has many read_* functions to read data from multiples data sources or formats like json, jdbc, excel, pickel (python serialized objects) etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"COLUMNS\"] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?CSV.File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#titanic_df = pd.csv(\"./data/titanic.csv\")\n",
    "\n",
    "\n",
    "titanic_df = CSV.File(\"./data/titanic.csv\") |> DataFrame\n",
    "#titanic_df = CSV.read(\"./data/titanic.csv\", DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reading file which is not in UTF-8 encoding (Say, ISO-8859-1), we may need StringEncodings.jl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the first few rows\n",
    "head() also takes an argument n, which specifies how many records will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#titanic.head()\n",
    "\n",
    "## To return only the first record\n",
    "first(titanic_df);\n",
    "head(titanic_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic.tail(10)\n",
    "\n",
    "tail(titanic_df,10);\n",
    "last(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary\n",
    "\n",
    "Use `describe` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df.describe()\n",
    "\n",
    "describe(titanic_df, :all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Get descriptive for Age and Fare column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(titanic_df, :all, cols=[:Age,:Fare])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Get descriptive for Sex and Embarked column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(titanic_df, :all, cols=[\"Sex\",\"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing - With Copy\n",
    "\n",
    "The df[:, :col] and df[:, cols] syntaxes always copy dataframes so they are safe to use (and should generally be preferred except for performance or memory critical use cases). You can also use copy(df). Below code use this syntax:\n",
    "* Select all rows across all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#titanic_df.iloc[:,:]\n",
    "\n",
    "titanic_df[:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Select 5 rows across first 3 columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df.iloc[0:5,0:3]\n",
    "\n",
    "titanic_df[1:5,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Select first 4 rows and first 3 columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df.iloc[:4,:3]\n",
    "\n",
    "titanic_df[1:4,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Select first 2 columns of the last row.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df.iloc[-1:,:2]\n",
    "\n",
    "titanic_df[end,1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Last 3 records can be selected this way.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_df[end-2:end,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Select first 3 records.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[1:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **First 2 columns not selected.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(titanic_df[:, Not(1:2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **First row not selected.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(titanic_df[Not(1),:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Select columns between two column names.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(titanic_df[:, Between(:Pclass, :Age)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Select the record of column whose name starts with \"A\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head(titanic_df[:, r\"A\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Select the record of column whose name starts with \"A\" but do not select the first record.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head(titanic_df[Not(1), r\"A\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`r` stands for Regex. One can write advanced Regex. \n",
    "\n",
    "## Indexing and Slicing - Without Copy\n",
    "\n",
    "**Caution**\n",
    "With df[!, :col] and df.col syntax you get a direct (non copying) access to a column of a data frame. This is potentially unsafe as you can easily corrupt data in the df data frame if you resize, sort, etc. the column obtained in this way. Therefore such access should be used with caution.\n",
    "\n",
    "Similarly df[!, cols] when cols is a collection of columns produces a new data frame that holds the same (not copied) columns as the source df data frame. Similarly, modifying the data frame obtained via df[!, cols] might cause problems with the consistency of df.\n",
    "\n",
    "! indicates that underlying columns are not copied. Ex: Select the record of column whose name starts with \"A\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(titanic_df[!, r\"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(titanic_df[!, Not(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Views\n",
    "\n",
    "Create a view of a DataFrame which is more efficient than creating a selection. Here are the possible return value options. Exactly the same syntax as slicing and indexing as above but for the `@view` prefixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(@view (titanic_df[:, r\"A\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@view titanic_df[1:4,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data type\n",
    "\n",
    "> * Data type\n",
    "* dimensions.. how many row and columns\n",
    "* Structure of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Dimensions of data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#?size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df.shape\n",
    "@show size(titanic_df)\n",
    "@show size(titanic_df, 1)\n",
    "@show size(titanic_df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow(titanic_df), ncol(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types. Each column has how many not-null values. `eltype` means element types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df.info()\n",
    "eltypes(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eltype.(eachcol(titanic_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Column names of titanic_df.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Column names as symbol.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "propertynames(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames.jl allows to use Symbols (like :A) and strings (like \"A\") for all column indexing operations for convenience. However, using Symbols is slightly faster and should generally be preferred, if not generating them via string manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Specific columns and rowsÂ¶\n",
    "\n",
    "> **Select the Survived column and display the first 5 entries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df[['Survived']][0:5]\n",
    "\n",
    "@view titanic_df[[\"Survived\"]][1:5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@view titanic_df[[\"Survived\"]][1:5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df[['Survived']].head(5)\n",
    "\n",
    "head(@view titanic_df[[\"Survived\"]],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The other way\n",
    "#titanic_df.Survived[0:5]\n",
    "    \n",
    "@view titanic_df.Survived[1:5,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the vector stored in the DataFrame without copying it. The `.` and `!` (stands for inplace) both can achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.\"Survived\"\n",
    "\n",
    "titanic_df.Survived\n",
    "\n",
    "titanic_df[!, [\"Survived\"]]\n",
    "\n",
    "head(titanic_df[!, [:Survived]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(titanic_df.Survived[1:5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax below will creates a copy (not advisable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(titanic_df[:, [\"Survived\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting multiple columns. \n",
    "\n",
    "Multiple column names should be provided as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df[['Survived','Age']].head()\n",
    "#titanic_df[['Survived','Age']][1:5]\n",
    "#titanic_df[['Survived','Age']].iloc[0:5,]\n",
    "\n",
    "head(@view titanic_df[:,[\"Survived\",\"Age\"]])\n",
    "@view titanic_df[:,[\"Survived\",\"Age\"]][1:6,:]\n",
    "@view titanic_df[:,[:Survived,:Age]][1:6,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a column using the `select()` function from DataFrames pacakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(select(titanic_df,[:Survived,:Age]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition based filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(titanic_df[(titanic_df.Pclass .== 1), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will work as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "size(titanic_df[(titanic_df.Pclass .== 1) .& (titanic_df.Sex .==\"male\"), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How many children below 5 years age were on board the ship**\n",
    "\n",
    "But this won't as there are missing values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[titanic_df.Age .<= 5.0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is missing value in a column, then condition filter gives error. In such cases, use coalesce. It return the first value in the arguments which is not equal to missing, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = titanic_df[(titanic_df.Age <=5) ]\n",
    "\n",
    "size(titanic_df[coalesce.(titanic_df.Age .<= 5.0, false), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Filter with just missing value in Age column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size(titanic_df[(ismissing.(titanic_df.Age)), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Filter with missing value and age <=5 years.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(titanic_df[(coalesce.(titanic_df.Age .<= 5.0, true)), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How many children survived who are less than 5 years old**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df [(titanic_df.Age <=5) & (titanic_df.Survived ==1)].shape\n",
    "\n",
    "size(titanic_df[coalesce.(titanic_df.Age .<=5, false) .& (titanic_df.Survived .==1),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df[(titanic_df.Age <= 5)].shape\n",
    "\n",
    "countmap((titanic_df[coalesce.(titanic_df.Age .<=5, false),:]).Survived);\n",
    "\n",
    "countmap((titanic_df[coalesce.(titanic_df.Age .<=5, false) .& (titanic_df.Survived .==1),:]).Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How many people survived and what is the percentage.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df[ titanic_df.Age <= 5].Survived.value_counts(normalize = True)\n",
    "\n",
    "proptable((titanic_df[coalesce.(titanic_df.Age .<=5, false),:]).Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Select Age, Sex and Pclass of passengers who survived and where less than 5 years old**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df[ (titanic_df.Age <= 5) &  \n",
    "#            (titanic_df.Survived ==1) ][['Age','Gender','Pclass']].head()\n",
    "\n",
    "head(titanic_df[coalesce.(titanic_df.Age, false) .<=5 .& \n",
    "                    (titanic_df.Survived .==1),[:Age, :Sex,:Pclass]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Only age, sex, survived and pclass of passengers whose age are not known.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#titanic_df[ titanic_df.Age.isnull() ][['Age','Gender','Pclass']].shape\n",
    "\n",
    "head(titanic_df[ismissing.(titanic_df.Age),[:Age, :Sex,:Pclass]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Only age, sex, survived and pclass of passengers whose age are known.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#titanic_df[ -titanic_df.Age.isnull() ][['Age','Gender','Pclass']][0:5]\n",
    "\n",
    "head(titanic_df[Not(ismissing.(titanic_df.Age)),[:Age, :Sex,:Pclass]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Several other ways of conditon based filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@which findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(row -> row.Sex==\"male\", titanic_df);\n",
    "\n",
    "filter(:Sex => ==(\"male\") , titanic_df);\n",
    "\n",
    "titanic_df[titanic_df.Sex .== \"male\", :];\n",
    "\n",
    "titanic_df[findall(==(\"male\"), titanic_df.Sex), :];\n",
    "\n",
    "titanic_df[isequal.(titanic_df.Pclass,2), :];\n",
    "\n",
    "titanic_df[findall(==(1), titanic_df.Pclass), :];\n",
    "\n",
    "titanic_df[findall(<=(1), titanic_df.Pclass), :];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get unique values for a column\n",
    "\n",
    "> **How many embark points were there.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df.Embarked.unique()\n",
    "\n",
    "unique(titanic_df.Embarked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How many missing value in Embarked column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countmap(titanic_df.Embarked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross tabulation of data\n",
    "\n",
    "> **Pivot gender with survived.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrames.combine(DataFrames.groupby(titanic_df,[:Sex,:Survived]), nrow => :count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(titanic_df.Sex, titanic_df.Survived, margins = True)\n",
    "\n",
    "FreqTbl= FreqTables.freqtable(titanic_df, :Sex, :Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(FreqTbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(DataFrame,FreqTbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename(convert(DataFrame,FreqTbl), Dict(:x1=>string(0),:x2=>string(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize by Rows\n",
    "\n",
    "If margins is 1 row proportions are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(titanic_df.Sex,titanic_df.Survived, margins=True, normalize='index')\n",
    "\n",
    "FreqTables.proptable(titanic_df,:Sex,:Survived, margins =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize by columns\n",
    "\n",
    "If margins is 2 column proportions are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(titanic_df.Sex,titanic_df.Survived, margins=True, normalize='columns')\n",
    "FreqTables.proptable(titanic_df,:Sex,:Survived, margins =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize by row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.crosstab(titanic_df.Sex,titanic_df.Survived, margins=True,normalize='all')\n",
    "\n",
    "FreqTables.proptable(titanic_df,:Sex,:Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation \n",
    "\n",
    "Getting summary statistics for a column can be done by using functions from DataFrames, StatsBase and FreqTable package.\n",
    "\n",
    "\n",
    "To know which package a function belogs to: use @which as a prefix. Say, you want to know which package the function combine belongs to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@which combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using statistics package\n",
    "DataFrames.combine(DataFrames.groupby(titanic_df,[:Survived]), nrow => :count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@which countmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df.Survived.value_counts()\n",
    "\n",
    "## using statsbase package\n",
    "StatsBase.countmap(titanic_df.Survived)\n",
    "#StatsBase.counts(titanic_df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df.Survived.value_counts(normalize = True)\n",
    "\n",
    "StatsBase.proportionmap(titanic_df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The other way\n",
    "#titanic_df['Survived'].value_counts()\n",
    "\n",
    "StatsBase.proportionmap(titanic_df[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using FreqTable package. Useful in Pivots as well. will see later\n",
    "FreqTables.freqtable(titanic_df.Survived, skipmissing=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqtable(titanic_df,:Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with NA Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ismissing just asks if the column itself is a missing type, which it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ismissing(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(ismissing.(titanic_df.Age))\n",
    "\n",
    "#all(ismissing.(titanic_df.Age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(ismissing.(titanic_df.Age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use replace!() if you want to repalce the missing value in the same column of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace(titanic_df.Age, missing=>1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way wherein we want to replace the missing value with some value, say 0 as well as apply more than one math operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@which ismissing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(x -> ismissing(x) ? 0.0 : [log(x),sqrt(x)], titanic_df.Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the value of of a selection using broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[1:2,[:Age,:SibSp]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The symbol `.` is for broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[1:2,[:Age,:SibSp]] .= [25,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop NA: Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@which dropmissing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Drop NA Values in Embarked column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#titanic_df.Embarked.dropna(inplace=False)\n",
    "\n",
    "size(dropmissing(titanic_df,:Embarked))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Remove rows where there are NA values in any of the columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_titanic_df = titanic_df.dropna()\n",
    "\n",
    "clean_titanic_df = dropmissing(titanic_df)\n",
    "size(clean_titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Look for missing in only cabin and delete the entire record if missing is found.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "head(dropmissing(titanic_df, :Cabin),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(dropmissing(titanic_df, [:Cabin,:Sex]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename a Column\n",
    "\n",
    "> **Rename \"Embarked\" column to \"onboarded\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df = titanic_df.rename(columns = {\"Embarked\": \"Onboarded\", \"Sex\": \"Gender\"}, inplace=False)\n",
    "\n",
    "head(rename(titanic_df, :Embarked=> :Onboarded, :Sex=>:Gender),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(rename(titanic_df, [:Embarked=> :Onboarded, :Sex=>:Gender]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(rename(titanic_df, Dict(:Embarked=> :Onboarded, :Sex=>:Gender)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(rename(uppercase,titanic_df),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To make the change to the original dataframe, use as rename!(). rename!() is similar to inplace parameter in pandas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby and Aggregate\n",
    "\n",
    "> **Find the average age of passengers based on Pclass column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# groupby+combine at the same time\n",
    "sort(@by(\n",
    "    titanic_df,[:Pclass], \n",
    "    first=first(:Age), \n",
    "    last=last(:Age),\n",
    "    mean=mean(skipmissing(:Age))\n",
    "    )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = groupby(titanic_df,[:Pclass]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the same as by but on grouped DataFrame\n",
    "\n",
    "sort(@combine(grouped_df, \n",
    "        first=first(:Age), \n",
    "        last=last(:Age), \n",
    "        mean=mean(skipmissing(:Age))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Compute several statistics on the grouped dataframe.** \n",
    "\n",
    "By using the combine function from DataFrames.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(combine(grouped_df, :Age .=> [first, last, mean]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Find the average age of passengers based on Pclass and Gender.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Python code\n",
    "#pclass_gender_age_df = titanic_df.groupby(['Pclass', 'Gender'])['Age'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using DataFramemeta package\n",
    "pclass_gender_age_df = @combine(groupby(titanic_df,[:Pclass,:Sex]),Avg=mean(skipmissing(:Age)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way, we can create a new dataframe with completecases for Pclass, Sex, Age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_complete_df = titanic_df[completecases(titanic_df[:,[:Pclass,:Sex,:Age]]),:]\n",
    "size(subset_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using DataFrame package\n",
    "pclass_gender_age_df = combine(groupby(subset_complete_df,[:Pclass,:Sex]),:Age.=>[mean,first,last,std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How many passengers survived in each of the pclass and for each of the gender.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pclass_gender_sur_df = titanic_df.groupby( ['Pclass', \"Gender\"] )[\"Survived\"].sum().reset_index()\n",
    "\n",
    "\n",
    "pclass_gender_sur_df = @combine(groupby(titanic_df,[:Pclass,:Sex]),Survived=sum(skipmissing(:Survived)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Dataframe\n",
    "\n",
    "> Merge pclass_gender_age_df with pclass_gender_sur_df based on pclass and Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pclass_gender_merge_df = pclass_gender_age_df.merge(pclass_gender_sur_df, on = ['Pclass','Gender'])\n",
    "\n",
    "pclass_gender_merge_df = innerjoin(pclass_gender_age_df,pclass_gender_sur_df,on = [\"Pclass\",\"Sex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort Values\n",
    "\n",
    "> Sort the pclass_gender_merge_df on Survived column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pclass_gender_merge_df.sort_values(\"Survived\", ascending=False)\n",
    "\n",
    "sort(pclass_gender_merge_df,[:Pclass,:Survived],rev=[false, false])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pclass_gender_merge_df.to_csv(\"merged_df.csv\")\n",
    "\n",
    "CSV.write(\"merged_df.csv\", pclass_gender_merge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "Using `pclass_gender_merge_df` do a visualization of Age and Survived w.r.t Pclass and Sex. What kind of charts will be meaningful here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the categorical and numeric features\n",
    "\n",
    "This is how we can do in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "\n",
    "#num_feat_list = [x for x in titanic_df.select_dtypes(include = np.number)]\n",
    "#num_feat_list\n",
    "\n",
    "#cat_feat_list = [x for x in titanic_df.select_dtypes(include = np.object)]\n",
    "#cat_feat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Base.nonmissingtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of categorical and numeric features in a dataset in Julia. The `<:` operator in general means \"is a subtype of\", and used in declarations as: \n",
    "\n",
    "* used in expressions as a subtype operator which returns true when its left operand is a subtype of its right operand\n",
    "* declares the right-hand type to be an immediate supertype of the newly declared type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_feat_list = names(titanic_df, String)\n",
    "\n",
    "num_feat_list = names(titanic_df[[i for i in names(titanic_df) if nonmissingtype(eltype(titanic_df[i])) <: Number]])\n",
    "\n",
    "#num_feat_list = names(titanic_df[(<:).(eltypes(titanic_df),Union{Number,Missing})])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_feat_list = names(titanic_df[[i for i in names(titanic_df) if Base.nonmissingtype(eltype(titanic_df[i])) <: String]])\n",
    "cat_feat_list = names(titanic_df[(<:).(eltypes(titanic_df),Union{String,Missing})])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefit is evident while summarizing and performing any other operation on features of the same type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(titanic_df, :all, cols=num_feat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new column\n",
    "\n",
    "> **Create a vector of ones which has the same size as length of titanic_df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@which ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllOnes = Base.ones(size(titanic_df,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Add the vector of ones to titanic_df.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[:, \"Add_Ones\"] = AllOnes; #Creates a copy\n",
    "head(titanic_df,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Check if the All_ones is a copy of the vector.** \n",
    "\n",
    "isequal, isless, and === produce results of type Bool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.Add_Ones === AllOnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False means that new memory was used and Add_ones is not refering to the vector of ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[!, \"Add_Ones_Again\"] = AllOnes; #Without creating a copy\n",
    "head(titanic_df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.Add_Ones_Again === AllOnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Add column named 'ImptAge' by replacing the missing values in 'Age' column with '1'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(insertcols!(titanic_df, 7, :ImptAge => replace(titanic_df.Age, missing=>1),makeunique=true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Adding a feature in the dataframe which is log of Age column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[!, \"LogAge1\"] = log.(titanic_df.Age)\n",
    "head(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Adding an index column in titanic_df.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertcols!(titanic_df, 1, :Sl_No => 1:size(titanic_df,1),makeunique=true)\n",
    "head(titanic_df,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hcat(), vcat() for horizontal or vertical concatnation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column - Lambda function with map\n",
    "\n",
    "Math operations to create new features can be referred: https://docs.julialang.org/en/v1/manual/mathematical-operations/. In case of missing value in a column, most math functions handle it. So we may compute as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@which sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(x -> [sqrt(x)], titanic_df[:,:Age])[1:6,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting with `.` operator after the function name also gives the same output. We will use broadcating to add columns later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sqrt.(titanic_df.Age)[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Transforming the new column 'ImptAge' by applying log function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titanic_df.logAge2 = map(x -> log(x), titanic_df[:,:ImptAge])\n",
    "head(titanic_df,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Create a Column named Gender and map Sex Column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_df['gender_code'] = titanic_df.Gender.map(lambda x: int(x =='male'))\n",
    "#titanic_df.iloc[0:4,]\n",
    "\n",
    "##One way\n",
    "titanic_df.gender_code1= map(x -> (x==\"male\") ? 1 : 0, titanic_df[:,:Sex])\n",
    "\n",
    "\n",
    "##The other way\n",
    "insertcols!(titanic_df, 7, :gender_code2 => map(x -> (x==\"male\") ? 1 : 0, titanic_df[:,:Sex]),makeunique=true);\n",
    "\n",
    "\n",
    "head(titanic_df,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Adding a feature in the dataframe which is square root of Age column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertcols!(titanic_df, 7, :SqrtAge => map(x -> sqrt(x), titanic_df[:,:Age]),makeunique=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add columns by broadcasting\n",
    "\n",
    "> **Adding Column of ones and zeroes by broadcasting.**\n",
    "\n",
    "The '.' operator stands for broadcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df[:, \"OneByBroadcast\"] .= 1;\n",
    "titanic_df[!, \"ZeoresByBroadcast\"] .= 0;\n",
    "head(titanic_df,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Adding a feature in the dataframe which is square root of Age column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We did this with lambda and map earlier. The other way\n",
    "insertcols!(titanic_df, 7, :SqrtAge =>sqrt.(titanic_df.Age),makeunique=true);\n",
    "\n",
    "head(titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined functions\n",
    "\n",
    "\n",
    "> **Define a function to find NA values and unique labels in any column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def find_na(name):\n",
    "#    return titanic_df[name].value_counts(dropna=False)\n",
    "\n",
    "function find_na(name)\n",
    "    return countmap(titanic_df[:,name])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def find_unique(name):\n",
    "#    return titanic_df[name].unique()\n",
    "\n",
    "function find_unique(name)\n",
    "    return unique(titanic_df[:,name])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_na(\"Embarked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_unique(\"Embarked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Define a function to perform cross tabulation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cross_tab(x,y):\n",
    "#    return pd.crosstab(titanic_df[x],titanic_df[y])\n",
    "\n",
    "function cross_tab(x,y)\n",
    "    return freqtable(titanic_df[:,x],titanic_df[:,y])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ct = (cross_tab(\"Sex\",\"Pclass\"))\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In Python\n",
    "#stacked_df = df.stack().reset_index().rename(columns={0:'percentage'})\n",
    "#stacked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn=names(ct,1);\n",
    "cn=names(ct,2);\n",
    "df=DataFrame(ct, Symbol.(cn))\n",
    "insertcols!(df, 1, :rowname => rn,makeunique=true)\n",
    "\n",
    "## This can also be done\n",
    "#df.rowname = rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Converting a dataframe from wide to long format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df = stack(df, [\"1\",\"2\",\"3\"],\"rowname\", variable_name = \"Pclass\",value_name =\"count\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Visualizing cross tabulated data created above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sn\n",
    "#sn.barplot(x='Pclass', y='percentage', hue='Gender', data = stacked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"Gadfly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gadfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 8cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp1 = Gadfly.plot(stack_df, \n",
    "    x=\"Pclass\",\n",
    "    y=\"count\", \n",
    "    Geom.bar(),\n",
    "    Theme(bar_spacing=1mm, key_position=:none),\n",
    "    Scale.color_discrete_manual(\"red\")\n",
    ")\n",
    "\n",
    "bp2 = Gadfly.plot(stack_df, \n",
    "    x=:Pclass,\n",
    "    y=:count, \n",
    "    color=:rowname, \n",
    "    Geom.bar(position=:dodge),\n",
    "    Theme(bar_spacing=1mm, key_position=:right),\n",
    "    Scale.color_discrete_manual(\"red\",\"green\")\n",
    ")\n",
    "\n",
    "hstack(bp1,bp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: \n",
    "\n",
    "1. Use the user defined function `find_na` and `find_unique` to get the value count and unique labels of all the categorical features in the titanic dataframe\n",
    "\n",
    "\n",
    "The commented code are in python. Think of converting it to Julia code with the syntaxes learnt in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "\n",
    "#cat_feat_list = [x for x in titanic_df.select_dtypes(include = np.object)]\n",
    "#cat_feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_feat_list.append(\"Survived\")\n",
    "#cat_feat_list.remove('Name')\n",
    "#cat_feat_list.remove('Ticket')\n",
    "#cat_feat_list.remove('Cabin')\n",
    "#cat_feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for c in cat_feat_list:\n",
    "#    find_na(c)\n",
    "#    find_unique(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(map(find_na, cat_feat_list)))\n",
    "#print(list(map(find_unique, cat_feat_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "\n",
    "2. Use the user defined function `cross_tab` to cross tabulate every pair of categorical features. \n",
    "\n",
    "The commented code are in python. Think of converting it to Julia code with the syntaxes learnt in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Method\n",
    "\n",
    "Cross tabulation of every pair of categorical feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in range(0,len(cat_feat_list)):\n",
    "#    for y in range(x+1,len(cat_feat_list)):\n",
    "#        #if x!=y:\n",
    "#            cross_tab(cat_feat_list[x],cat_feat_list[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import itertools\n",
    "#for p in itertools.combinations(cat_feat_list, 2):\n",
    "#    cross_tab(*p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: DIY\n",
    "3. Change the cross_tab function to report the nomalized values by rows and columns. Perform visulization for each pair of categorical variable. What kind of charts will be meaningful here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Topics: Working with Other file formats\n",
    "\n",
    "XML, JSON , BSON, YAML , MessagePack, and protobuf are some commonly used data serialization formats.\n",
    "\n",
    "JDF is a serailization format supported by Julia. JDF stores a DataFrame in a folder with each column stored as a separate file. There is also a metadata.jls file that stores metadata about the original DataFrame. Collectively, the column files, the metadata file, and the folder is called a JDF \"file\".\n",
    "\n",
    "JDF.jl is a pure-Julia solution and there are a lot of ways to do nifty things like compression and encapsulating the underlying struture of the arrays that's hard to do in R and Python. E.g. Python's numpy arrays are C objects, but all the vector types used in JDF are Julia data types.\n",
    "\n",
    "JDF is a DataFrames serialization format with the following goals\n",
    "\n",
    "* Fast save and load times\n",
    "* Compressed storage on disk\n",
    "* Enable disk-based data manipulation (not yet achieved; from v0.4.0)\n",
    "* Supports machine learning workloads, e.g. mini-batch, sampling (not yet achieved; from v0.4.0)\n",
    "\n",
    "\n",
    "More here: https://github.com/xiaodaigh/JDF.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JDF.save(\"merged_df.jdf\", pclass_gender_merge_df);\n",
    "\n",
    "JDF.save(\"titanic.jdf\", titanic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "If the columns names in the dataframe have the same name, JDF.save will overwrite the saved file. Thus, while using JDF.load(), it may error out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_jdf = JDF.load(\"titanic.jdf\") |> DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Create an object which is a on disk representation of `titanic_df`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "titanic_ondisk = jdf\"titanic.jdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(titanic_ondisk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Load only Age and Pclass.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf_df = JDF.load(titanic_ondisk; cols = [\"Age\", \"Pclass\"]) |> DataFrame\n",
    "head(jdf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other file formats:\n",
    "\n",
    "* JSONTables.jl: To do read and write data in JSON format.\n",
    "* Arrow.jl: Apache Arrow format that allows, in particular, for data interchange with R or Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack and Unstack - Wide - Long - Wide format\n",
    "\n",
    "pclass_gender_age_df  created earlier is in wide format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(pclass_gender_age_df,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Select Age_mean and Age_Std to convert it into long format.**\n",
    "\n",
    "Pass measure variables and then id-variable. Renaming variable is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df = stack(pclass_gender_age_df, [:Age_mean,:Age_std], [:Pclass,:Sex],\n",
    "    variable_name=\"key\", value_name=\"observed\") # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Convert the stack_df created above into long format.**\n",
    "\n",
    "Without key (the column name in above df) no unstacking can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unstack(stack_df, [:Pclass,:Sex], :key, :observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Wide format with all variable and no renaming of columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_df = stack(pclass_gender_age_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Convert the stack_df created above into long format.**\n",
    "\n",
    "The name variable in above dataframe is the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstack(stack_df, [:Pclass,:Sex], :variable, :value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
